# convnext-small-metadata-fusion-ham10000
Multi-modal skin lesion classification on the HAM10000 dataset using ConvNeXt-Small for image analysis and clinical metadata fusion (age, sex, localization). Includes training pipeline, class imbalance handling, and evaluation with detailed metrics.
Multi-Modal Skin Lesion Classification Using ConvNeXt-Small and Clinical Metadata

In this experiment, we propose a multi-modal deep learning framework that integrates dermoscopic images with patient metadata for skin lesion classification on the HAM10000 dataset. The visual branch is based on ConvNeXt-Small, a modern convolutional architecture pre-trained on ImageNet, while the metadata branch processes structured clinical information including age, sex, and lesion localization using a lightweight multilayer perceptron (MLP). Patient age values were normalized, missing values were imputed using the mean, and categorical variables were encoded via one-hot encoding. The outputs of both branches were concatenated and jointly optimized for final prediction across seven diagnostic categories.

The dataset was split into training (80%) and validation (20%) subsets using stratified sampling to preserve class distribution. To address severe class imbalance, class weights were computed and applied during training. Images were resized to 224×224 pixels and processed using a tf.data pipeline for efficient loading. The ConvNeXt-Small backbone was initially frozen, and only the classification head and metadata branch were trained. The model was optimized using the Adam optimizer with sparse categorical cross-entropy loss and early stopping based on validation loss.

The proposed multi-modal ConvNeXt-Small model achieved a validation accuracy of 71.79%. Notably, the model demonstrated improved recall for underrepresented classes such as df (dermatofibroma) and vasc (vascular lesions) compared to image-only models. The weighted F1-score reached 0.74, indicating better overall balance between precision and recall in the presence of class imbalance.

When compared with earlier image-only approaches—including DenseNet121, EfficientNetB0, and other CNN-based baselines—the multi-modal ConvNeXt-Small framework consistently delivered superior performance. DenseNet121 suffered from limited generalization after fine-tuning, while EfficientNetB0, although more parameter-efficient, achieved a lower validation accuracy of 69.90% and weaker recall on rare classes. The improvement observed with ConvNeXt-Small highlights the benefit of combining high-capacity modern CNNs with auxiliary clinical metadata, especially in challenging medical datasets with skewed class distributions.

The source codes for DenseNet121 and EfficientNetB0 models are provided in separate GitHub repositories for reproducibility and direct comparison. All experiments were conducted using the HAM10000 skin lesion dataset, available at:
https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000
